---
# Variables listed here are applicable to all

# some operations could be time consuming and users may want to skip them
# totally even though they are idempotent
step_switch:
  nic: yes
  hostname: yes
  selinux: yes
  ssh_key: yes
  partition: yes
  repo: yes
  ntp: yes

# each host must set ceph_network_ip and vm_network_ip
network_interfaces:
  - name: ceph_network
    nic: eth0
    prefix: 24
    network: 10.21.1.0
    use_bonding: no
    ip_addr_ref: ceph_network_ip

  - name: vm_network
    nic: eth1
    prefix: 24
    network: 10.21.1.0
    use_bonding: no
    ip_addr_ref: vm_network_ip
    
# switch used to control ceph type
# valid values: S_HDD, E_HDD, SSD
# S_HDD: hdd-based cluster, provide large volume disks
# E_HDD: hdd-based cluster, provide large, and higher performance disk 
# SSD: ssd-based cluster, provide highest performance disk
#
ClUSTER_TYPE: "S_HDD"

#when deploy openstack we need admin keyring if cephx is enabled
#openstack glance-api and nova-compute support only one backend,
#so it should be set to "yes" only once;if you wanna glance-api and nova-compute
#use this "ClUSTER_TYPE" backend, set it to yes;
COPY_KEYRING: no

# Below is variables used to create local repo
#
INTERNAL_REPO_ENABLED: yes

INTERNAL_CENTOS_REPO_HOST: "220.231.201.236"
INTERNAL_CEPH_REPO_HOST: "123.59.199.64"
#when deploy ceph use public network internal repo,
#we need uncomment sslclientcert and sslclientkey,also do it in repo.yml file
#also edit "http" to https,

INTERNAL_REPO_MIRRORS:
  - name: epel
    file: epel
    baseurl: "http://{{ INTERNAL_CENTOS_REPO_HOST }}/data/centos/epel-chinac/$releasever/$basearch/"
  - name: base
    file: CentOS-Base
    baseurl: "http://{{ INTERNAL_CENTOS_REPO_HOST }}/data/centos7-2/mirror.centos.org/centos-7/$releasever/os/$basearch/"
  - name: updates
    file: CentOS-Base
    baseurl: "http://{{ INTERNAL_CENTOS_REPO_HOST }}/data/centos7-2/mirror.centos.org/centos-7/$releasever/updates/$basearch/"
  - name: extras
    file: CentOS-Base
    baseurl: "http://{{ INTERNAL_CENTOS_REPO_HOST }}/data/centos7-2/mirror.centos.org/centos-7/$releasever/extras/$basearch/"
  - name: Ceph-noarch
    file: ceph-jewel
    baseurl: "https://{{ INTERNAL_CEPH_REPO_HOST }}/repos/ceph/jemalloc/noarch/"
    priority: 1   
    sslverify: 0
    sslclientcert: "/etc/pki/chinac/yum.pem"
    sslclientkey: "/etc/pki/chinac/yum-key.pem"
  - name: Ceph-x86_64
    file: ceph-jewel
    baseurl: "https://{{ INTERNAL_CEPH_REPO_HOST }}/repos/ceph/jemalloc/x86_64/"
    priority: 1 
    sslverify: 0
    sslclientcert: "/etc/pki/chinac/yum.pem"
    sslclientkey: "/etc/pki/chinac/yum-key.pem"


PIP_REPO_MIRROR_HOST: pypi.mirrors.ustc.edu.cn

# in order to support multiple osds on single disk, partitions maybe used for data store,
# so from now, paritions are used for two types: OSD or journal
# for OSD type, the name value should start with "data", such as data01 or data02
# for journal type, the name value should start with "journal", such as journal01 or journal02
disk_partition_layouts:
  disk_partition_layout1:
    - device: vdb
      partitions:
      - percent: [4096s, 100%]
        name: journal01
        filesystem: xfs
 
# if you don't have a seperate journal, please set steps.partition to no
ceph_osd_layouts:
  # 1 SSD is sed as SATA journal
  ceph_osd_layout_1:
    - device: vda
      use_cache: no
      cache: vdb1
      use_type: yes
      type: hdd
    - device: vdb
      use_cache: no
      cache: vdb1
      use_type: yes
      type: hdd
    - device: vdc
      use_cache: no
      cache: vdb2
      use_type: yes
      type: hdd
   
ceph_osd_layout_map:
  tt-master:
    partition: disk_partition_layout1
    osd: ceph_osd_layout_1
  tt-slave1:
    partition: disk_partition_layout1
    osd: ceph_osd_layout_1
 
ceph_management_dir: /root/ceph-management/
 
# vim: ft=yaml:shiftwidth=2:tabstop=2:expandtab:softtabstop=2
